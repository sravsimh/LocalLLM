# LocalLLM
This project is to create a benchmark software to run on a loacal machine to benchmark the performance of a LLM and determine if it is beneficial to run locally or to infer over cloud.
